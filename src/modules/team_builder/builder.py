
"""
Team formation that balances:
- Fit to project (candidate-project similarity)
- Diversity / complementarity (penalize similarity to current team)
- Skill/tool coverage (marginal gain in required skills/tools)
- Role coverage (embedding-based satisfaction of project required_roles)

Optional GenAI touch:
- LLM reranker among top-K candidates at each step (only if OPENAI_API_KEY is set)

Supports:
- build_teams_sequential_greedy(): disjoint teams, team1 strongest
- build_teams_round_robin(): disjoint teams, more balanced
- build_teams_auto(): if n_teams==1 => greedy else round robin
- summarize_teams_for_ui(): per-team missing skills/tools/roles + fit + redundancy stats
"""

from __future__ import annotations

import os
import json
import logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any

import numpy as np
from shared.interfaces import CandidateProfile, ProjectDescription

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

try:
    from sentence_transformers import SentenceTransformer  
except Exception:
    SentenceTransformer = None



# Artifacts + role embeddings (for required_roles)


PROJECT_ROOT = Path(__file__).resolve().parents[3]
ARTIFACT_DIR = PROJECT_ROOT / "data" / "artifacts"

_DEFAULT_ROLE_MODEL = "all-MiniLM-L6-v2"
_role_model = None  


def _get_role_model(model_name: str = _DEFAULT_ROLE_MODEL):
    global _role_model
    if SentenceTransformer is None:
        return None
    if _role_model is None:
        _role_model = SentenceTransformer(model_name)
    return _role_model


def _load_candidate_embeddings_from_artifacts() -> Tuple[Optional[np.ndarray], Optional[List[str]]]:
    """
    Loads candidate embeddings generated by your pipeline:
      data/artifacts/candidate_embeddings.npy
      data/artifacts/candidate_ids.json
    """
    emb_path = ARTIFACT_DIR / "candidate_embeddings.npy"
    ids_path = ARTIFACT_DIR / "candidate_ids.json"

    if not emb_path.exists() or not ids_path.exists():
        return None, None

    try:
        embs = np.load(str(emb_path))
        ids = json.loads(ids_path.read_text(encoding="utf-8"))
        ids = [str(x) for x in ids]
        return embs, ids
    except Exception as e:
        logger.info(f"Failed loading candidate embeddings artifacts: {e}")
        return None, None


def _embed_role_queries(required_roles: List[str], model_name: str = _DEFAULT_ROLE_MODEL) -> Optional[np.ndarray]:
    """
    Embeds role labels with the same transformer family as your pipeline.
    Role query text is simple and consistent:
      'Required role: Developer, mobile'
    """
    required_roles = [str(r).strip() for r in (required_roles or []) if str(r).strip()]
    if not required_roles:
        return None

    model = _get_role_model(model_name)
    if model is None:
        return None

    texts = [f"Required role: {r}" for r in required_roles]
    return model.encode(texts, normalize_embeddings=True)


def _roles_missing_embedding(
    required_roles: List[str],
    team_member_ids: List[str],
    *,
    threshold: float = 0.55,
    model_name: str = _DEFAULT_ROLE_MODEL,
    cand_embs: Optional[np.ndarray] = None,
    cand_ids: Optional[List[str]] = None,
) -> List[str]:
    """
    A role is satisfied if ANY team member has cosine similarity >= threshold
    to the role query embedding.

    This is purely embedding-based (no manual mapping), consistent with your schema.
    """
    required_roles = [str(r).strip() for r in (required_roles or []) if str(r).strip()]
    if not required_roles:
        return []

    if cand_embs is None or cand_ids is None:
        cand_embs, cand_ids = _load_candidate_embeddings_from_artifacts()

    if cand_embs is None or cand_ids is None or len(cand_ids) == 0:
        # Can't evaluate roles semantically => treat all as missing
        return list(required_roles)

    role_embs = _embed_role_queries(required_roles, model_name=model_name)
    if role_embs is None:
        return list(required_roles)

    idx = {cid: i for i, cid in enumerate(cand_ids)}

    missing: List[str] = []
    for role_label, role_vec in zip(required_roles, role_embs):
        best = 0.0
        for mid in team_member_ids:
            if mid in idx:
                best = max(best, float(np.dot(role_vec, cand_embs[idx[mid]])))
        if best < float(threshold):
            missing.append(role_label)

    return missing



# Normalization helpers


def _norm(s: str) -> str:
    return (s or "").strip().lower()


def _team_item_set(team: List[CandidateProfile]) -> set[str]:
    out: set[str] = set()
    for m in team:
        out.update({_norm(x) for x in (m.skills or []) if x})
        out.update({_norm(x) for x in (m.tools or []) if x})
    return out


def _candidate_item_set(c: CandidateProfile) -> set[str]:
    return set([_norm(x) for x in (c.skills or []) if x] + [_norm(x) for x in (c.tools or []) if x])


def _safe_fit(project_similarities: Dict[str, float], cid: str) -> float:
    try:
        return float(project_similarities.get(cid, 0.0))
    except Exception:
        return 0.0


# Coverage / diversity


def coverage_gain(team: List[CandidateProfile], candidate: CandidateProfile, required_items: List[str]) -> float:
    """Marginal gain in required skill/tool coverage by adding candidate (0..1)."""
    req = {_norm(x) for x in (required_items or []) if x}
    if not req:
        return 0.0

    team_items = _team_item_set(team)
    cand_items = _candidate_item_set(candidate)

    before = len(req & team_items)
    after = len(req & (team_items | cand_items))
    return (after - before) / max(1, len(req))


def avg_similarity_to_team(
    candidate_id: str,
    team_ids: List[str],
    sim_matrix: Optional[np.ndarray],
    candidate_ids_order: List[str],
) -> float:
    """Average similarity between candidate and current team members. Returns 0 if missing."""
    if sim_matrix is None or not team_ids:
        return 0.0

    idx = {cid: i for i, cid in enumerate(candidate_ids_order)}
    if candidate_id not in idx:
        return 0.0

    ci = idx[candidate_id]
    sims = []
    for tid in team_ids:
        if tid in idx:
            sims.append(float(sim_matrix[ci, idx[tid]]))
    return float(sum(sims) / len(sims)) if sims else 0.0


def overlap_redundancy(team: List[CandidateProfile], cand: CandidateProfile) -> float:
    """
    Penalize skill/tool overlap redundancy using explicit set overlap.
    Returns 0..1 (share of candidate items already in team).
    """
    cand_items = _candidate_item_set(cand)
    if not cand_items:
        return 0.0
    team_items = _team_item_set(team)
    return float(len(cand_items & team_items) / len(cand_items))


def role_gain(
    team: List[CandidateProfile],
    cand: CandidateProfile,
    required_roles: List[str],
    *,
    role_threshold: float = 0.55,
    role_model: str = _DEFAULT_ROLE_MODEL,
    cand_embs: Optional[np.ndarray] = None,
    cand_ids_for_emb: Optional[List[str]] = None,
) -> float:
    """
    Embedding-based role gain (0..1):
    - compute missing roles BEFORE adding cand
    - compute missing roles AFTER adding cand
    - gain = (missing_before - missing_after) / len(required_roles)
    """
    required_roles = [str(r).strip() for r in (required_roles or []) if str(r).strip()]
    if not required_roles:
        return 0.0

    team_ids = [m.id for m in team]

    missing_before = _roles_missing_embedding(
        required_roles=required_roles,
        team_member_ids=team_ids,
        threshold=role_threshold,
        model_name=role_model,
        cand_embs=cand_embs,
        cand_ids=cand_ids_for_emb,
    )
    if not missing_before:
        return 0.0

    missing_after = _roles_missing_embedding(
        required_roles=required_roles,
        team_member_ids=team_ids + [cand.id],
        threshold=role_threshold,
        model_name=role_model,
        cand_embs=cand_embs,
        cand_ids=cand_ids_for_emb,
    )

    covered_now = len(missing_before) - len(missing_after)
    return float(covered_now / max(1, len(required_roles)))



# LLM reranker


def llm_choose_best_candidate(
    team: List[CandidateProfile],
    shortlist: List[CandidateProfile],
    project: ProjectDescription,
    project_similarities: Dict[str, float],
    sim_matrix: Optional[np.ndarray],
    candidate_ids_order: List[str],
    model: str = "gpt-4.1-mini",
) -> Optional[str]:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or OpenAI is None:
        return None

    client = OpenAI(api_key=api_key)
    team_ids = [m.id for m in team]
    missing_required = sorted(set([_norm(x) for x in (project.required_skills or []) if x]) - _team_item_set(team))

    def brief(m: CandidateProfile) -> Dict[str, Any]:
        return {
            "id": m.id,
            "role": m.role,
            "availability_hours": m.availability_hours,
            "collaboration_style": m.collaboration_style,
            "skills": (m.skills or [])[:20],
            "tools": (m.tools or [])[:20],
            "fit": _safe_fit(project_similarities, m.id),
        }

    def cand_brief(c: CandidateProfile) -> Dict[str, Any]:
        team_items = _team_item_set(team)
        cand_items = _candidate_item_set(c)
        add_req = sorted(set([_norm(x) for x in (project.required_skills or []) if x]) & (cand_items - team_items))
        return {
            **brief(c),
            "avg_similarity_to_team": avg_similarity_to_team(c.id, team_ids, sim_matrix, candidate_ids_order),
            "adds_required_items": add_req,
        }

    payload = {
        "project": {
            "title": project.title,
            "required_roles": project.required_roles,
            "required_skills": project.required_skills,
            "team_size": project.team_size,
        },
        "current_team": [brief(m) for m in team],
        "missing_required_items": missing_required,
        "shortlist": [cand_brief(c) for c in shortlist],
        "rules": [
            "Pick exactly ONE candidate from shortlist.",
            "Prefer candidates that add missing required skills/tools.",
            "Prefer lower avg_similarity_to_team (less redundancy).",
            "Consider role balance if required_roles are given.",
            "Do not invent skills or facts; use only provided data."
        ],
        "output_format": {
            "best_candidate_id": "string (must be in shortlist)",
            "reason": "short string",
        }
    }

    prompt = (
        "You are a team composition critic. Choose the best next candidate.\n"
        "Return JSON ONLY.\n"
        f"{json.dumps(payload, indent=2)}"
    )

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=220,
        )
        txt = (resp.choices[0].message.content or "").strip()
        a, b = txt.find("{"), txt.rfind("}")
        if a == -1 or b == -1:
            return None
        obj = json.loads(txt[a:b + 1])
        chosen = obj.get("best_candidate_id")
        if chosen and chosen in {c.id for c in shortlist}:
            return str(chosen)
        return None
    except Exception as e:
        logger.info(f"LLM rerank skipped (fallback). Reason: {e}")
        return None



# Scorer (shared)

def score_candidate_for_team(
    team: List[CandidateProfile],
    cand: CandidateProfile,
    project: ProjectDescription,
    candidate_sim_matrix: Optional[np.ndarray],
    candidate_ids_order: List[str],
    project_similarities: Dict[str, float],
    *,
    alpha: float = 0.55,   # fit
    beta: float = 0.25,    # diversity
    gamma: float = 0.20,   # coverage gain
    rho: float = 0.10,     # role gain (soft)
    delta_overlap: float = 0.15,  # overlap redundancy penalty
   
    role_threshold: float = 0.55,
    role_model: str = _DEFAULT_ROLE_MODEL,
    cand_embs: Optional[np.ndarray] = None,
    cand_ids_for_emb: Optional[List[str]] = None,
) -> float:
    fit = _safe_fit(project_similarities, cand.id)
    gain_cov = coverage_gain(team, cand, project.required_skills)

    team_ids = [m.id for m in team]
    avg_sim = avg_similarity_to_team(cand.id, team_ids, candidate_sim_matrix, candidate_ids_order)
    diversity = 1.0 - avg_sim

    rg = role_gain(
        team, cand, project.required_roles,
        role_threshold=role_threshold,
        role_model=role_model,
        cand_embs=cand_embs,
        cand_ids_for_emb=cand_ids_for_emb,
    )
    ov = overlap_redundancy(team, cand)

    return float((alpha * fit) + (gamma * gain_cov) + (beta * diversity) + (rho * rg) - (delta_overlap * ov))

# 

class TeamBuilderGenAI:
    def __init__(
        self,
        alpha: float = 0.55,
        beta: float = 0.25,
        gamma: float = 0.20,
        rho: float = 0.10,
        delta_overlap: float = 0.15,
        fit_threshold: float = 0.0,
        rerank_top_k: int = 5,
        use_llm_rerank: bool = True,
        llm_model: str = "gpt-4.1-mini",
        min_availability_hours: int = 0,
       
        role_threshold: float = 0.55,
        role_model: str = _DEFAULT_ROLE_MODEL,
    ):
        self.alpha = float(alpha)
        self.beta = float(beta)
        self.gamma = float(gamma)
        self.rho = float(rho)
        self.delta_overlap = float(delta_overlap)

        self.fit_threshold = float(fit_threshold)
        self.rerank_top_k = int(rerank_top_k)
        self.min_availability_hours = int(min_availability_hours)

        self.role_threshold = float(role_threshold)
        self.role_model = str(role_model)

       
        self.cand_embs, self.cand_ids_for_emb = _load_candidate_embeddings_from_artifacts()

        self.use_llm_rerank = bool(use_llm_rerank and os.getenv("OPENAI_API_KEY") and OpenAI is not None)
        self.llm_model = llm_model

        if use_llm_rerank and not self.use_llm_rerank:
            logger.info("LLM reranker disabled (no OPENAI_API_KEY or openai pkg missing).")

    def build_team_greedy(
        self,
        profiles: List[CandidateProfile],
        project: ProjectDescription,
        candidate_sim_matrix: Optional[np.ndarray],
        candidate_ids: List[str],
        project_similarities: Dict[str, float],
    ) -> List[CandidateProfile]:
        if not profiles:
            return []

        # availability filter
        filtered_av = [p for p in profiles if int(p.availability_hours or 0) >= self.min_availability_hours]
        if not filtered_av:
            filtered_av = list(profiles)

     
        filtered = [p for p in filtered_av if _safe_fit(project_similarities, p.id) >= self.fit_threshold]
        if not filtered:
            filtered = list(filtered_av)

     
        filtered.sort(key=lambda p: _safe_fit(project_similarities, p.id), reverse=True)
        team = [filtered[0]]
        remaining = [p for p in filtered[1:]]

        while len(team) < int(project.team_size) and remaining:
            scored: List[Tuple[float, CandidateProfile]] = []
            for cand in remaining:
                sc = score_candidate_for_team(
                    team, cand, project,
                    candidate_sim_matrix, candidate_ids, project_similarities,
                    alpha=self.alpha, beta=self.beta, gamma=self.gamma, rho=self.rho,
                    delta_overlap=self.delta_overlap,
                    role_threshold=self.role_threshold,
                    role_model=self.role_model,
                    cand_embs=self.cand_embs,
                    cand_ids_for_emb=self.cand_ids_for_emb,
                )
                scored.append((sc, cand))
            scored.sort(key=lambda x: x[0], reverse=True)

            shortlist = [c for _, c in scored[: max(1, self.rerank_top_k)]]

            chosen_id = None
            if self.use_llm_rerank and len(shortlist) >= 2:
                chosen_id = llm_choose_best_candidate(
                    team=team,
                    shortlist=shortlist,
                    project=project,
                    project_similarities=project_similarities,
                    sim_matrix=candidate_sim_matrix,
                    candidate_ids_order=candidate_ids,
                    model=self.llm_model,
                )

            chosen = None
            if chosen_id:
                chosen = next((c for c in remaining if c.id == chosen_id), None)
            if chosen is None:
                chosen = scored[0][1]

            team.append(chosen)
            remaining = [p for p in remaining if p.id != chosen.id]

        return 

def build_teams_sequential_greedy(
    profiles: List[CandidateProfile],
    project: ProjectDescription,
    candidate_sim_matrix: Optional[np.ndarray],
    candidate_ids: List[str],
    project_similarities: Dict[str, float],
    *,
    min_availability_hours: int = 0,
    n_teams: Optional[int] = None,
    pool_size: int = 200,
    builder_kwargs: Optional[Dict[str, Any]] = None,
) -> List[List[CandidateProfile]]:
    team_size = int(project.team_size or 0)
    if team_size <= 0:
        return []

    eligible = [p for p in profiles if int(p.availability_hours or 0) >= int(min_availability_hours)]
    if not eligible:
        eligible = list(profiles)

    # restrict to ids we can score diversity for
    ids_set = set(candidate_ids)
    eligible = [p for p in eligible if p.id in ids_set]

    eligible.sort(key=lambda p: _safe_fit(project_similarities, p.id), reverse=True)
    eligible = eligible[: max(int(pool_size), team_size)]

    max_possible = len(eligible) // team_size
    if max_possible <= 0:
        return []

    if n_teams is None:
        n_teams = max_possible
    else:
        n_teams = max(1, min(int(n_teams), max_possible))

    bk = builder_kwargs or {}
    builder = TeamBuilderGenAI(min_availability_hours=min_availability_hours, **bk)

    remaining = list(eligible)
    teams: List[List[CandidateProfile]] = []

    for _ in range(int(n_teams)):
        team = builder.build_team_greedy(remaining, project, candidate_sim_matrix, candidate_ids, project_similarities)
        if len(team) < team_size:
            break
        teams.append(team)

        chosen_ids = {m.id for m in team}
        remaining = [p for p in remaining if p.id not in chosen_ids]
        if len(remaining) < team_size:
            break

    return teams


def build_teams_round_robin(
    profiles: List[CandidateProfile],
    project: ProjectDescription,
    candidate_sim_matrix: Optional[np.ndarray],
    candidate_ids: List[str],
    project_similarities: Dict[str, float],
    *,
    min_availability_hours: int = 0,
    n_teams: int = 2,
    pool_size: int = 200,
    builder_kwargs: Optional[Dict[str, Any]] = None,
) -> List[List[CandidateProfile]]:
    team_size = int(project.team_size or 0)
    if team_size <= 0 or int(n_teams) <= 0:
        return []

    eligible = [p for p in profiles if int(p.availability_hours or 0) >= int(min_availability_hours)]
    if not eligible:
        eligible = list(profiles)

    ids_set = set(candidate_ids)
    eligible = [p for p in eligible if p.id in ids_set]

    eligible.sort(key=lambda p: _safe_fit(project_similarities, p.id), reverse=True)

    need_min = int(n_teams) * team_size
    pool_n = max(int(pool_size), need_min)
    pool = eligible[:pool_n]

    bk = builder_kwargs or {}
    builder = TeamBuilderGenAI(min_availability_hours=min_availability_hours, **bk)

    teams: List[List[CandidateProfile]] = [[] for _ in range(int(n_teams))]
    used: set[str] = set()

    for _round in range(team_size):
        for t in range(int(n_teams)):
            remaining = [p for p in pool if p.id not in used]
            if not remaining:
                break

            team = teams[t]

            scored = []
            for cand in remaining:
                sc = score_candidate_for_team(
                    team, cand, project,
                    candidate_sim_matrix, candidate_ids, project_similarities,
                    alpha=builder.alpha, beta=builder.beta, gamma=builder.gamma,
                    rho=builder.rho, delta_overlap=builder.delta_overlap,
                    role_threshold=builder.role_threshold,
                    role_model=builder.role_model,
                    cand_embs=builder.cand_embs,
                    cand_ids_for_emb=builder.cand_ids_for_emb,
                )
                scored.append((sc, cand))
            scored.sort(key=lambda x: x[0], reverse=True)

            shortlist = [c for _, c in scored[: max(1, builder.rerank_top_k)]]
            chosen = None

            if builder.use_llm_rerank and len(shortlist) >= 2:
                chosen_id = llm_choose_best_candidate(
                    team=team,
                    shortlist=shortlist,
                    project=project,
                    project_similarities=project_similarities,
                    sim_matrix=candidate_sim_matrix,
                    candidate_ids_order=candidate_ids,
                    model=builder.llm_model,
                )
                if chosen_id:
                    chosen = next((c for c in shortlist if c.id == chosen_id), None)

            if chosen is None:
                chosen = scored[0][1]

            teams[t].append(chosen)
            used.add(chosen.id)

    full = [t for t in teams if len(t) == team_size]
    return full


def build_teams_auto(
    profiles: List[CandidateProfile],
    project: ProjectDescription,
    candidate_sim_matrix: Optional[np.ndarray],
    candidate_ids: List[str],
    project_similarities: Dict[str, float],
    *,
    min_availability_hours: int = 0,
    n_teams: int = 1,
    pool_size: int = 200,
    builder_kwargs: Optional[Dict[str, Any]] = None,
) -> List[List[CandidateProfile]]:
    if int(n_teams) <= 1:
        return build_teams_sequential_greedy(
            profiles, project, candidate_sim_matrix, candidate_ids, project_similarities,
            min_availability_hours=min_availability_hours,
            n_teams=1,
            pool_size=pool_size,
            builder_kwargs=builder_kwargs,
        )
    return build_teams_round_robin(
        profiles, project, candidate_sim_matrix, candidate_ids, project_similarities,
        min_availability_hours=min_availability_hours,
        n_teams=int(n_teams),
        pool_size=pool_size,
        builder_kwargs=builder_kwargs,
    )



# #SUMMERIES FOR UI


def summarize_teams_for_ui(
    teams: List[List[CandidateProfile]],
    project: ProjectDescription,
    project_similarities: Dict[str, float],
    candidate_sim_matrix: Optional[np.ndarray] = None,
    candidate_ids_order: Optional[List[str]] = None,
    *,
    role_threshold: float = 0.55,
    role_model: str = _DEFAULT_ROLE_MODEL,
) -> Dict[str, Any]:
    # Project requirements (normalized)
    req_items = {_norm(x) for x in (project.required_skills or []) if x}
    req_roles = [str(x).strip() for x in (project.required_roles or []) if str(x).strip()]

   
    req_items_specified = len(req_items) > 0
    req_roles_specified = len(req_roles) > 0

    cand_embs, cand_ids_for_emb = _load_candidate_embeddings_from_artifacts()

    out_teams: List[Dict[str, Any]] = []

    for idx, team in enumerate(teams, start=1):
        team_ids = [m.id for m in team]

        team_items = _team_item_set(team)
        covered = sorted(list(req_items & team_items))
        missing = sorted(list(req_items - team_items))

       
        missing_roles = _roles_missing_embedding(
            required_roles=req_roles,
            team_member_ids=team_ids,
            threshold=role_threshold,
            model_name=role_model,
            cand_embs=cand_embs,
            cand_ids=cand_ids_for_emb,
        )

        fits = [_safe_fit(project_similarities, m.id) for m in team]
        avg_fit = float(sum(fits) / max(1, len(fits)))

        avg_internal_sim = 0.0
        if candidate_sim_matrix is not None and candidate_ids_order is not None and len(team_ids) >= 2:
            idx_map = {cid: i for i, cid in enumerate(candidate_ids_order)}
            sims = []
            for i in range(len(team_ids)):
                for j in range(i + 1, len(team_ids)):
                    a = team_ids[i]
                    b = team_ids[j]
                    if a in idx_map and b in idx_map:
                        sims.append(float(candidate_sim_matrix[idx_map[a], idx_map[b]]))
            avg_internal_sim = float(sum(sims) / len(sims)) if sims else 0.0

        cov_pct = 100.0 if not req_items else (100.0 * len(covered) / len(req_items))

       
        technical_coverage_summary = {
          
            "required_items_specified": bool(req_items_specified),
            "required_roles_specified": bool(req_roles_specified),

            
            "items_covered": None if not req_items_specified else (len(missing) == 0),
            "roles_covered": None if not req_roles_specified else (len(missing_roles) == 0),

            
            "coverage_percent": round(float(cov_pct), 2),
            "covered_items": covered,
            "missing_items": missing,
            "missing_roles": missing_roles,
        }

        out_teams.append({
            "team_number": idx,
            "size": len(team),

           
            "coverage_percent": round(float(cov_pct), 2),
            "covered_items": covered,
            "missing_items": missing,
            "missing_roles": missing_roles,

            "avg_fit": round(avg_fit, 4),
            "avg_internal_similarity": round(avg_internal_sim, 4),
            "member_ids": team_ids,

           
            "technical_coverage_summary": technical_coverage_summary,
        })

    return {
        "n_teams": len(out_teams),
        "team_size": int(project.team_size or 0),
        "required_items_count": len(req_items),
        "required_roles_count": len(req_roles),
        "teams": out_teams,
    }
